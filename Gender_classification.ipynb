{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gender_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNshZbIu/If2jV9LYb5dx2N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zainal-77/Gender-Classification/blob/main/Gender_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "jSARL5gnAscE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "\t  rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\"gender-recognition-200k-images-celeba/Dataset/Train/\",\n",
        "                                                    batch_size =256 ,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (64, 64))     \n",
        "\n",
        "validation_generator =  test_datagen.flow_from_directory( \"gender-recognition-200k-images-celeba/Dataset/Validation/\",\n",
        "                                                          batch_size  = 256,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (64, 64))"
      ],
      "metadata": {
        "id": "t-mqsVEOAuPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "model = tf.keras.models.Sequential([\n",
        "    # 1st conv\n",
        "  tf.keras.layers.Conv2D(96, (11,11),strides=(4,4), activation='relu', input_shape=(64, 64, 3)),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.MaxPooling2D(2, strides=(2,2)),\n",
        "    # 2nd conv\n",
        "  tf.keras.layers.Conv2D(256, (11,11),strides=(1,1), activation='relu',padding=\"same\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "     # 3rd conv\n",
        "  tf.keras.layers.Conv2D(384, (3,3),strides=(1,1), activation='relu',padding=\"same\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "    # 4th conv\n",
        "  tf.keras.layers.Conv2D(384, (3,3),strides=(1,1), activation='relu',padding=\"same\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "    # 5th Conv\n",
        "  tf.keras.layers.Conv2D(256, (3, 3), strides=(1, 1), activation='relu',padding=\"same\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.MaxPooling2D(2, strides=(2, 2)),\n",
        "  # To Flatten layer\n",
        "  tf.keras.layers.Flatten(),\n",
        "  # To FC layer 1\n",
        "  tf.keras.layers.Dense(4096, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  #To FC layer 2\n",
        "  tf.keras.layers.Dense(4096, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "model.compile(\n",
        "    optimizer=Adam(lr=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "   )\n",
        "hist = model.fit_generator(generator=train_generator,\n",
        "                    validation_data=validation_generator,\n",
        "                    steps_per_epoch=256,\n",
        "                    validation_steps=256,\n",
        "                    epochs=50)"
      ],
      "metadata": {
        "id": "5tJb2kehA1VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LT-5FDzCAv_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "from keras.preprocessing import image\n",
        "# predicting images\n",
        "path = \"gender-recognition-200k-images-celeba/Dataset/Test/Female/160001.jpg\"\n",
        "img = image.load_img(path, target_size=(64, 64))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "images = np.vstack([x])\n",
        "classes = model.predict(images, batch_size=1)\n",
        "print(classes[0])\n",
        "if classes[0]>0.5:\n",
        "    print(\"is a man\")\n",
        "else:\n",
        "    print( \" is a female\")\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "3oPw2CKRA2Di"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}